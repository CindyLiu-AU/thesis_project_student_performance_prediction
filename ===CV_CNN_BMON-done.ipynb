{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM, Masking, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "from keras.layers import Activation,Flatten\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM, Masking, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "from keras.layers import Activation,Flatten\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPool1D, Dropout, Activation\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_ori=pd.read_csv('BBB_planB_monthly.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T0_Act1</th>\n",
       "      <th>T0_Act12</th>\n",
       "      <th>T0_Act13</th>\n",
       "      <th>T0_Act14</th>\n",
       "      <th>T0_Act19</th>\n",
       "      <th>T0_Act2</th>\n",
       "      <th>T0_Act3</th>\n",
       "      <th>T0_Act4</th>\n",
       "      <th>T0_Act5</th>\n",
       "      <th>T0_Act6</th>\n",
       "      <th>...</th>\n",
       "      <th>T9_Act19</th>\n",
       "      <th>T9_Act2</th>\n",
       "      <th>T9_Act3</th>\n",
       "      <th>T9_Act4</th>\n",
       "      <th>T9_Act5</th>\n",
       "      <th>T9_Act6</th>\n",
       "      <th>T9_Act7</th>\n",
       "      <th>T9_Act9</th>\n",
       "      <th>id</th>\n",
       "      <th>final_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_23629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_25107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_29144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_31663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_34229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2014J_2688945</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2014J_2692969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2014J_2694919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5339</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2014J_2698577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5340</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2014J_2698588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5341 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T0_Act1  T0_Act12  T0_Act13  T0_Act14  T0_Act19  T0_Act2  T0_Act3  \\\n",
       "0        12.0       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "1         3.0       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "2         0.0       0.0       0.0       0.0       0.0      1.0      3.0   \n",
       "3       119.0       0.0       2.0       3.0       0.0      1.0     44.0   \n",
       "4         7.0       0.0       0.0       0.0       0.0      0.0      2.0   \n",
       "...       ...       ...       ...       ...       ...      ...      ...   \n",
       "5336      0.0       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "5337     66.0       0.0       0.0       1.0       0.0     26.0      4.0   \n",
       "5338      0.0       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "5339      0.0       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "5340      0.0       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "\n",
       "      T0_Act4  T0_Act5  T0_Act6  ...  T9_Act19  T9_Act2  T9_Act3  T9_Act4  \\\n",
       "0         2.0      0.0      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "1         2.0      0.0      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "2         5.0      0.0      1.0  ...       0.0      0.0      0.0      0.0   \n",
       "3       103.0      0.0     35.0  ...       0.0      0.0      0.0      0.0   \n",
       "4         8.0      0.0      1.0  ...       0.0      0.0      0.0      0.0   \n",
       "...       ...      ...      ...  ...       ...      ...      ...      ...   \n",
       "5336      0.0      0.0      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "5337     33.0      0.0      8.0  ...       0.0      0.0      0.0     26.0   \n",
       "5338      0.0      0.0      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "5339      0.0      0.0      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "5340      0.0      0.0      0.0  ...       0.0      4.0      0.0      4.0   \n",
       "\n",
       "      T9_Act5  T9_Act6  T9_Act7  T9_Act9                 id  final_result  \n",
       "0         0.0      0.0      0.0      0.0    BBB_2013B_23629             0  \n",
       "1         0.0      0.0      0.0      0.0    BBB_2013B_25107             1  \n",
       "2         0.0      0.0      0.0      0.0    BBB_2013B_29144             0  \n",
       "3         0.0      0.0      0.0      0.0    BBB_2013B_31663             1  \n",
       "4         0.0      0.0      0.0      0.0    BBB_2013B_34229             1  \n",
       "...       ...      ...      ...      ...                ...           ...  \n",
       "5336      0.0      0.0      0.0      0.0  BBB_2014J_2688945             1  \n",
       "5337      0.0      0.0      0.0      0.0  BBB_2014J_2692969             1  \n",
       "5338      0.0      0.0      0.0      0.0  BBB_2014J_2694919             1  \n",
       "5339      0.0      0.0      0.0      0.0  BBB_2014J_2698577             0  \n",
       "5340      0.0      0.0      0.0      0.0  BBB_2014J_2698588             1  \n",
       "\n",
       "[5341 rows x 122 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T0_Act1</th>\n",
       "      <th>T0_Act12</th>\n",
       "      <th>T0_Act13</th>\n",
       "      <th>T0_Act14</th>\n",
       "      <th>T0_Act19</th>\n",
       "      <th>T0_Act2</th>\n",
       "      <th>T0_Act3</th>\n",
       "      <th>T0_Act4</th>\n",
       "      <th>T0_Act5</th>\n",
       "      <th>T0_Act6</th>\n",
       "      <th>...</th>\n",
       "      <th>T9_Act19</th>\n",
       "      <th>T9_Act2</th>\n",
       "      <th>T9_Act3</th>\n",
       "      <th>T9_Act4</th>\n",
       "      <th>T9_Act5</th>\n",
       "      <th>T9_Act6</th>\n",
       "      <th>T9_Act7</th>\n",
       "      <th>T9_Act9</th>\n",
       "      <th>id</th>\n",
       "      <th>final_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_1008675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_104054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_108377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_108589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_1098728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_109938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_110881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_116603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_117071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBB_2013B_120994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T0_Act1  T0_Act12  T0_Act13  T0_Act14  T0_Act19  T0_Act2  T0_Act3  \\\n",
       "1093     32.0       0.0       1.0       0.0       0.0      0.0      3.0   \n",
       "31        3.0       0.0       0.0       2.0       0.0      1.0      7.0   \n",
       "32      165.0       0.0       9.0       3.0       0.0      2.0     17.0   \n",
       "33       29.0       0.0       0.0       0.0       0.0      3.0     11.0   \n",
       "1094      0.0       0.0       0.0       0.0       0.0      3.0      3.0   \n",
       "34        0.0       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "35        0.0       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "36       67.0       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "37        0.0       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "38        0.0       0.0       0.0       0.0       0.0      0.0      0.0   \n",
       "\n",
       "      T0_Act4  T0_Act5  T0_Act6  ...  T9_Act19  T9_Act2  T9_Act3  T9_Act4  \\\n",
       "1093      6.0      0.0      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "31       17.0      0.0      4.0  ...       0.0      0.0      0.0      0.0   \n",
       "32       71.0      1.0      5.0  ...       0.0      0.0      0.0      0.0   \n",
       "33       11.0      0.0      6.0  ...       0.0      0.0      0.0      0.0   \n",
       "1094      8.0      0.0      3.0  ...       0.0      0.0      0.0      0.0   \n",
       "34        0.0      0.0      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "35        0.0      0.0      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "36       17.0      0.0      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "37        0.0      0.0      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "38        0.0      0.0      0.0  ...       0.0      0.0      0.0      0.0   \n",
       "\n",
       "      T9_Act5  T9_Act6  T9_Act7  T9_Act9                 id  final_result  \n",
       "1093      0.0      0.0      0.0      0.0  BBB_2013B_1008675             1  \n",
       "31        0.0      0.0      0.0      0.0   BBB_2013B_104054             1  \n",
       "32        0.0      0.0      0.0      0.0   BBB_2013B_108377             1  \n",
       "33        0.0      0.0      0.0      0.0   BBB_2013B_108589             1  \n",
       "1094      0.0      0.0      0.0      0.0  BBB_2013B_1098728             0  \n",
       "34        0.0      0.0      0.0      0.0   BBB_2013B_109938             1  \n",
       "35        0.0      0.0      0.0      0.0   BBB_2013B_110881             1  \n",
       "36        0.0      0.0      0.0      0.0   BBB_2013B_116603             1  \n",
       "37        0.0      0.0      0.0      0.0   BBB_2013B_117071             0  \n",
       "38        0.0      0.0      0.0      0.0   BBB_2013B_120994             0  \n",
       "\n",
       "[10 rows x 122 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_sorted=df1_ori.sort_values(by=['id'])\n",
    "df1_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare dataset for y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5341,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df1_sorted['final_result']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare dataset for X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df1_sorted.drop(['final_result','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5341, 120)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(5341,120,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=42, shuffle=True)\n",
      "TRAIN: [   0    1    2 ... 5337 5339 5340] TEST: [   8   15   23   29   33   65   79   80   84   88  106  107  132  144\n",
      "  151  157  167  168  179  199  227  228  230  239  240  245  248  251\n",
      "  254  272  279  290  292  296  297  315  333  346  351  373  393  401\n",
      "  410  416  418  422  426  439  443  465  468  471  472  485  486  491\n",
      "  497  501  505  530  534  538  544  553  555  577  584  589  599  624\n",
      "  625  626  642  653  655  683  691  696  705  721  724  734  742  746\n",
      "  748  751  763  776  787  794  798  803  807  810  811  812  829  838\n",
      "  848  881  898  907  911  915  926  957  964  969  977  994  996 1020\n",
      " 1025 1032 1038 1044 1049 1073 1084 1086 1094 1103 1126 1128 1158 1163\n",
      " 1168 1173 1188 1194 1197 1209 1215 1220 1223 1281 1292 1302 1319 1322\n",
      " 1330 1344 1351 1360 1397 1406 1411 1412 1421 1438 1468 1471 1476 1477\n",
      " 1480 1487 1504 1526 1533 1553 1557 1561 1580 1612 1615 1618 1620 1623\n",
      " 1652 1658 1665 1666 1669 1672 1705 1743 1744 1745 1755 1780 1782 1786\n",
      " 1807 1820 1832 1839 1864 1869 1877 1891 1902 1907 1945 1966 1988 1995\n",
      " 2015 2018 2022 2029 2031 2042 2045 2053 2057 2059 2063 2067 2072 2078\n",
      " 2083 2095 2099 2104 2107 2114 2133 2173 2181 2186 2217 2218 2231 2242\n",
      " 2268 2277 2280 2298 2303 2304 2323 2329 2333 2342 2346 2347 2348 2367\n",
      " 2369 2384 2388 2389 2404 2405 2414 2417 2418 2420 2437 2456 2457 2459\n",
      " 2463 2473 2487 2488 2518 2521 2522 2525 2533 2549 2555 2594 2603 2615\n",
      " 2619 2620 2633 2641 2642 2643 2647 2651 2654 2659 2677 2704 2751 2753\n",
      " 2754 2755 2765 2801 2809 2819 2822 2826 2833 2851 2862 2867 2886 2894\n",
      " 2917 2960 2962 2968 2985 2990 2998 3008 3034 3049 3053 3066 3074 3076\n",
      " 3084 3091 3095 3098 3102 3137 3142 3148 3163 3176 3194 3206 3207 3211\n",
      " 3259 3265 3269 3271 3276 3303 3311 3315 3317 3318 3322 3334 3351 3360\n",
      " 3365 3371 3375 3392 3396 3407 3408 3425 3431 3434 3437 3438 3442 3469\n",
      " 3470 3479 3536 3554 3555 3562 3565 3605 3606 3607 3631 3646 3647 3649\n",
      " 3679 3680 3683 3700 3714 3716 3721 3768 3770 3773 3782 3820 3824 3826\n",
      " 3829 3838 3874 3878 3882 3898 3901 3907 3916 3951 3963 3970 3980 3984\n",
      " 4023 4024 4025 4028 4032 4037 4048 4074 4083 4088 4093 4098 4101 4154\n",
      " 4162 4165 4166 4176 4181 4184 4189 4204 4211 4245 4253 4255 4259 4275\n",
      " 4278 4284 4296 4301 4315 4316 4317 4323 4326 4332 4333 4334 4336 4347\n",
      " 4355 4356 4358 4368 4369 4371 4381 4383 4387 4390 4399 4408 4418 4428\n",
      " 4466 4473 4476 4528 4545 4546 4552 4577 4603 4604 4612 4616 4625 4638\n",
      " 4661 4662 4665 4670 4674 4679 4681 4683 4696 4706 4707 4709 4716 4722\n",
      " 4749 4751 4756 4790 4816 4826 4829 4860 4866 4868 4876 4889 4892 4898\n",
      " 4903 4906 4917 4949 4952 4966 4982 4985 4994 5017 5041 5052 5057 5059\n",
      " 5061 5064 5070 5088 5091 5094 5095 5111 5112 5128 5137 5154 5195 5219\n",
      " 5228 5229 5260 5265 5270 5275 5280 5290 5297 5304 5313 5326 5328 5333\n",
      " 5335 5336 5338]\n",
      "TRAIN: [   0    1    2 ... 5337 5338 5340] TEST: [  12   17   26   43   47   51   61   63   69   70   75   90   93   95\n",
      "   96  100  102  109  120  121  135  149  177  181  184  195  203  210\n",
      "  219  221  233  238  252  287  291  308  322  334  339  350  354  367\n",
      "  371  381  387  414  415  428  429  437  438  457  478  527  533  549\n",
      "  561  566  582  586  596  598  605  621  633  644  652  654  657  670\n",
      "  676  677  681  693  711  712  718  731  733  745  747  757  764  765\n",
      "  800  802  805  828  831  833  842  856  865  877  879  889  893  896\n",
      "  925  931  932  944  952 1001 1002 1010 1022 1029 1034 1039 1041 1047\n",
      " 1055 1057 1074 1075 1090 1095 1101 1115 1117 1121 1129 1144 1175 1176\n",
      " 1200 1210 1212 1224 1231 1235 1244 1253 1255 1260 1261 1272 1297 1305\n",
      " 1321 1323 1335 1338 1345 1361 1371 1374 1392 1400 1405 1419 1425 1432\n",
      " 1433 1437 1448 1454 1456 1467 1483 1491 1498 1499 1501 1503 1505 1509\n",
      " 1513 1532 1538 1543 1545 1564 1566 1578 1583 1586 1606 1611 1630 1632\n",
      " 1643 1650 1657 1684 1703 1718 1732 1741 1756 1765 1773 1808 1815 1817\n",
      " 1822 1837 1840 1859 1860 1871 1876 1878 1879 1888 1892 1893 1921 1926\n",
      " 1937 1957 1961 1964 1971 1973 1978 1983 2004 2016 2025 2034 2077 2091\n",
      " 2093 2094 2101 2110 2115 2124 2135 2138 2144 2145 2146 2157 2172 2177\n",
      " 2182 2187 2201 2215 2222 2224 2226 2229 2244 2245 2254 2259 2264 2273\n",
      " 2275 2282 2292 2299 2305 2312 2339 2377 2380 2395 2399 2402 2416 2445\n",
      " 2464 2481 2503 2513 2527 2552 2561 2569 2574 2575 2584 2585 2586 2591\n",
      " 2596 2602 2614 2627 2629 2644 2646 2650 2673 2685 2686 2689 2694 2696\n",
      " 2698 2723 2726 2732 2742 2746 2760 2780 2788 2820 2834 2835 2850 2865\n",
      " 2874 2879 2883 2887 2890 2895 2897 2910 2927 2929 2932 2939 2941 2945\n",
      " 2957 2973 2974 2996 3011 3012 3013 3014 3038 3044 3058 3064 3071 3085\n",
      " 3090 3094 3103 3112 3113 3134 3143 3149 3150 3153 3162 3168 3169 3200\n",
      " 3210 3213 3235 3244 3246 3274 3298 3307 3346 3393 3403 3404 3443 3458\n",
      " 3475 3481 3515 3539 3541 3543 3559 3563 3571 3575 3580 3590 3601 3604\n",
      " 3614 3617 3650 3655 3659 3667 3671 3685 3693 3708 3711 3718 3724 3745\n",
      " 3749 3793 3814 3841 3848 3856 3865 3867 3891 3896 3904 3917 3939 3942\n",
      " 3948 3982 4002 4005 4011 4022 4050 4056 4059 4063 4072 4076 4080 4094\n",
      " 4095 4096 4103 4109 4119 4122 4128 4153 4157 4167 4194 4207 4230 4235\n",
      " 4240 4271 4283 4287 4292 4377 4396 4402 4403 4419 4424 4446 4461 4462\n",
      " 4478 4504 4511 4538 4549 4553 4557 4573 4575 4594 4606 4619 4626 4663\n",
      " 4668 4689 4699 4700 4713 4743 4755 4759 4762 4765 4767 4772 4784 4789\n",
      " 4820 4824 4830 4836 4844 4845 4872 4877 4879 4900 4914 4924 4934 4939\n",
      " 4941 4959 4962 4963 4969 4988 4993 4998 5005 5008 5013 5014 5029 5033\n",
      " 5039 5040 5042 5044 5045 5084 5097 5098 5100 5102 5138 5157 5182 5186\n",
      " 5187 5197 5207 5208 5209 5214 5221 5244 5245 5249 5255 5278 5312 5323\n",
      " 5324 5339]\n",
      "TRAIN: [   0    1    2 ... 5337 5338 5339] TEST: [  14   19   31   45   62   68   73   92   99  108  111  113  122  124\n",
      "  134  139  150  152  166  175  180  188  191  192  196  198  205  211\n",
      "  214  218  220  247  257  270  274  278  283  289  295  298  305  309\n",
      "  312  314  318  326  332  356  360  366  368  376  378  402  420  432\n",
      "  445  450  451  452  461  463  476  490  494  495  508  511  517  535\n",
      "  551  565  567  568  594  602  604  618  627  650  668  679  680  701\n",
      "  706  708  720  752  756  759  777  789  790  841  843  859  862  864\n",
      "  869  871  887  927  937  945  949  960  999 1006 1018 1024 1027 1042\n",
      " 1052 1056 1061 1096 1108 1114 1116 1135 1149 1162 1164 1170 1174 1181\n",
      " 1183 1187 1192 1204 1216 1221 1225 1242 1258 1263 1268 1270 1293 1295\n",
      " 1334 1340 1370 1375 1379 1391 1413 1420 1424 1427 1434 1436 1451 1485\n",
      " 1512 1514 1520 1534 1536 1539 1541 1550 1554 1569 1592 1593 1595 1599\n",
      " 1600 1616 1617 1626 1634 1647 1670 1691 1694 1702 1717 1723 1726 1728\n",
      " 1729 1740 1747 1779 1803 1818 1831 1835 1844 1849 1862 1873 1881 1894\n",
      " 1897 1905 1919 1954 1992 2002 2024 2098 2100 2111 2118 2127 2131 2142\n",
      " 2154 2191 2194 2197 2209 2210 2213 2223 2233 2235 2252 2276 2284 2288\n",
      " 2302 2309 2316 2317 2344 2357 2364 2366 2372 2407 2409 2422 2432 2439\n",
      " 2441 2447 2458 2480 2484 2486 2495 2499 2505 2512 2519 2534 2554 2576\n",
      " 2580 2589 2600 2609 2638 2653 2722 2727 2748 2767 2771 2776 2804 2805\n",
      " 2810 2812 2813 2818 2843 2846 2847 2855 2857 2873 2876 2881 2899 2905\n",
      " 2921 2925 2937 2944 2951 2977 2980 2988 2992 3007 3032 3039 3050 3080\n",
      " 3089 3101 3109 3125 3126 3128 3133 3135 3159 3164 3166 3181 3197 3204\n",
      " 3252 3253 3254 3268 3277 3286 3299 3320 3321 3326 3333 3340 3349 3352\n",
      " 3353 3357 3366 3378 3379 3384 3390 3402 3454 3455 3463 3468 3473 3478\n",
      " 3482 3493 3505 3516 3529 3537 3542 3548 3574 3576 3592 3611 3620 3624\n",
      " 3625 3634 3652 3654 3661 3662 3686 3690 3691 3699 3705 3707 3729 3732\n",
      " 3765 3767 3783 3796 3804 3807 3811 3831 3834 3842 3846 3857 3879 3889\n",
      " 3892 3897 3910 3914 3918 3922 3929 3931 3934 3941 3958 3965 3966 3967\n",
      " 3971 3996 3999 4020 4034 4044 4060 4069 4133 4137 4145 4151 4163 4168\n",
      " 4187 4198 4210 4219 4226 4262 4265 4272 4273 4279 4291 4294 4303 4307\n",
      " 4310 4311 4313 4314 4320 4335 4339 4340 4346 4354 4362 4370 4398 4412\n",
      " 4434 4479 4480 4482 4501 4502 4505 4516 4521 4523 4524 4525 4556 4567\n",
      " 4570 4576 4587 4595 4601 4607 4624 4627 4632 4633 4639 4645 4660 4664\n",
      " 4677 4678 4688 4691 4708 4711 4714 4719 4720 4730 4732 4742 4753 4763\n",
      " 4771 4774 4776 4783 4810 4812 4815 4821 4839 4863 4870 4885 4886 4894\n",
      " 4899 4910 4928 4937 4947 4974 4977 4983 4996 5000 5002 5009 5018 5023\n",
      " 5027 5046 5071 5074 5086 5089 5125 5127 5148 5149 5153 5158 5162 5166\n",
      " 5173 5175 5188 5190 5196 5216 5238 5240 5250 5251 5253 5256 5274 5301\n",
      " 5318 5340]\n",
      "TRAIN: [   0    1    2 ... 5338 5339 5340] TEST: [  24   25   30   32   44   52   56   58   76   81  103  112  136  138\n",
      "  156  170  174  183  194  208  217  229  256  259  263  266  276  286\n",
      "  293  299  319  321  324  325  328  330  336  353  358  382  408  411\n",
      "  413  430  433  436  442  449  479  498  506  507  518  540  543  557\n",
      "  564  576  611  613  615  620  622  643  647  648  665  682  690  695\n",
      "  725  736  744  755  761  783  785  796  801  809  817  818  835  857\n",
      "  888  897  903  908  910  912  941  978  990 1003 1017 1023 1033 1046\n",
      " 1051 1068 1071 1088 1097 1102 1106 1113 1119 1123 1146 1151 1157 1161\n",
      " 1172 1178 1180 1186 1189 1196 1207 1211 1222 1227 1228 1237 1238 1257\n",
      " 1264 1288 1303 1309 1313 1315 1350 1362 1378 1383 1393 1401 1402 1407\n",
      " 1417 1426 1444 1469 1479 1482 1488 1489 1497 1507 1510 1519 1522 1551\n",
      " 1552 1556 1558 1588 1589 1590 1598 1609 1610 1614 1627 1629 1654 1662\n",
      " 1675 1697 1699 1700 1714 1720 1721 1730 1736 1738 1739 1746 1751 1752\n",
      " 1760 1767 1769 1770 1777 1784 1788 1789 1813 1833 1858 1867 1870 1872\n",
      " 1874 1886 1890 1909 1912 1918 1924 1932 1934 1941 1942 1946 1962 1965\n",
      " 1972 2005 2052 2080 2086 2092 2103 2117 2119 2121 2153 2164 2167 2168\n",
      " 2170 2195 2225 2227 2228 2232 2236 2251 2287 2291 2311 2314 2318 2321\n",
      " 2328 2330 2337 2341 2351 2370 2373 2379 2387 2394 2406 2436 2440 2451\n",
      " 2462 2465 2471 2497 2515 2516 2517 2526 2536 2543 2559 2570 2572 2592\n",
      " 2598 2605 2611 2617 2622 2640 2655 2658 2663 2664 2670 2678 2699 2702\n",
      " 2705 2706 2749 2750 2757 2758 2759 2763 2770 2775 2778 2787 2792 2794\n",
      " 2802 2815 2829 2845 2856 2858 2859 2877 2882 2885 2902 2908 2915 2916\n",
      " 2922 2940 2991 3023 3029 3035 3043 3062 3065 3075 3077 3100 3121 3127\n",
      " 3129 3151 3161 3172 3185 3193 3196 3221 3240 3243 3248 3263 3270 3273\n",
      " 3282 3288 3306 3309 3323 3331 3339 3358 3362 3364 3370 3372 3381 3382\n",
      " 3388 3400 3412 3413 3429 3439 3450 3456 3471 3483 3487 3489 3492 3494\n",
      " 3499 3504 3540 3589 3593 3608 3615 3618 3619 3628 3641 3668 3684 3694\n",
      " 3698 3715 3727 3728 3737 3739 3742 3751 3754 3755 3774 3792 3795 3800\n",
      " 3803 3813 3822 3827 3835 3836 3839 3855 3858 3861 3875 3881 3887 3888\n",
      " 3906 3919 3940 3946 3975 3976 3988 4009 4010 4017 4036 4073 4084 4087\n",
      " 4105 4112 4129 4148 4155 4174 4214 4217 4220 4247 4250 4257 4267 4290\n",
      " 4299 4306 4322 4329 4373 4386 4391 4392 4400 4425 4440 4441 4445 4456\n",
      " 4458 4467 4481 4486 4512 4515 4517 4520 4531 4535 4536 4540 4543 4550\n",
      " 4554 4559 4562 4568 4578 4581 4585 4593 4600 4609 4615 4617 4651 4652\n",
      " 4657 4686 4704 4710 4717 4734 4738 4746 4750 4770 4786 4793 4794 4809\n",
      " 4814 4822 4846 4856 4862 4874 4895 4916 4920 4921 4956 4958 4968 4991\n",
      " 4992 5001 5003 5004 5020 5037 5050 5063 5065 5073 5079 5093 5096 5120\n",
      " 5124 5131 5174 5184 5189 5202 5218 5235 5239 5259 5263 5268 5294 5295\n",
      " 5298 5302]\n",
      "TRAIN: [   1    2    3 ... 5338 5339 5340] TEST: [   0    6    7   48   67   82   97  131  141  155  162  173  176  178\n",
      "  193  204  209  222  246  258  264  267  268  288  331  342  343  370\n",
      "  383  386  396  397  423  434  446  484  500  528  531  532  546  547\n",
      "  550  554  558  570  572  573  578  581  610  612  617  631  637  639\n",
      "  640  658  660  669  678  700  727  729  771  773  781  816  820  836\n",
      "  839  840  847  852  866  874  875  880  883  904  905  909  921  923\n",
      "  929  930  942  948  958  965  967  976  979  981  985 1011 1064 1085\n",
      " 1089 1091 1104 1105 1110 1127 1130 1138 1143 1152 1159 1171 1185 1201\n",
      " 1213 1226 1233 1236 1251 1277 1278 1289 1298 1299 1320 1325 1336 1356\n",
      " 1366 1372 1377 1395 1398 1422 1429 1431 1449 1450 1455 1457 1461 1464\n",
      " 1474 1490 1502 1515 1517 1537 1563 1565 1572 1594 1602 1621 1641 1642\n",
      " 1644 1649 1659 1683 1698 1727 1749 1758 1774 1781 1783 1787 1790 1793\n",
      " 1800 1812 1814 1829 1842 1846 1861 1880 1885 1896 1898 1900 1903 1904\n",
      " 1910 1915 1928 1935 1936 1943 1952 1967 1974 1991 2007 2011 2014 2019\n",
      " 2021 2028 2036 2069 2073 2088 2096 2097 2123 2174 2178 2189 2208 2211\n",
      " 2220 2221 2238 2240 2248 2266 2267 2269 2274 2290 2295 2297 2301 2307\n",
      " 2308 2313 2315 2319 2331 2354 2361 2374 2378 2413 2423 2426 2438 2450\n",
      " 2470 2476 2478 2492 2498 2509 2523 2531 2535 2550 2577 2607 2610 2623\n",
      " 2648 2656 2662 2669 2671 2680 2683 2687 2688 2692 2700 2707 2714 2715\n",
      " 2718 2721 2728 2741 2784 2789 2803 2807 2827 2841 2868 2892 2893 2900\n",
      " 2907 2942 2952 2954 2972 2987 3000 3001 3002 3017 3033 3045 3047 3070\n",
      " 3082 3105 3107 3114 3119 3130 3132 3138 3139 3154 3187 3214 3217 3247\n",
      " 3250 3256 3257 3258 3279 3285 3337 3386 3399 3406 3409 3410 3411 3414\n",
      " 3418 3422 3424 3428 3435 3459 3464 3485 3497 3501 3518 3519 3520 3523\n",
      " 3527 3535 3551 3552 3557 3558 3603 3621 3626 3630 3656 3658 3664 3682\n",
      " 3692 3702 3706 3712 3725 3750 3752 3757 3758 3771 3779 3781 3788 3806\n",
      " 3808 3809 3815 3819 3825 3837 3844 3852 3859 3862 3864 3866 3872 3877\n",
      " 3886 3903 3905 3909 3957 3961 3964 3986 3992 3994 4003 4006 4008 4012\n",
      " 4013 4019 4026 4038 4041 4053 4058 4078 4085 4092 4100 4127 4144 4147\n",
      " 4160 4161 4173 4183 4195 4201 4213 4215 4216 4233 4236 4241 4248 4254\n",
      " 4260 4264 4280 4281 4305 4318 4342 4348 4351 4359 4361 4366 4379 4384\n",
      " 4394 4395 4397 4405 4407 4421 4422 4438 4439 4443 4444 4460 4477 4484\n",
      " 4489 4500 4508 4513 4529 4532 4539 4547 4563 4572 4584 4591 4596 4618\n",
      " 4620 4621 4622 4628 4655 4669 4684 4685 4687 4695 4701 4712 4725 4766\n",
      " 4768 4775 4788 4792 4797 4804 4805 4806 4831 4838 4840 4849 4852 4857\n",
      " 4864 4888 4904 4905 4908 4913 4919 4922 4927 4943 4955 4981 4999 5012\n",
      " 5030 5043 5058 5075 5081 5103 5109 5129 5136 5143 5144 5151 5159 5160\n",
      " 5169 5170 5172 5176 5179 5181 5194 5201 5210 5212 5217 5227 5232 5288\n",
      " 5300 5303]\n",
      "TRAIN: [   0    1    2 ... 5338 5339 5340] TEST: [  22   41   57   59   78   86   87   91  104  115  118  123  147  163\n",
      "  172  182  187  212  226  231  234  237  243  261  265  282  313  340\n",
      "  347  361  363  365  369  389  392  398  399  405  407  421  424  435\n",
      "  448  456  460  462  464  475  480  487  496  509  521  522  541  542\n",
      "  560  593  597  601  632  641  651  656  662  685  689  697  702  707\n",
      "  739  741  758  767  772  779  782  799  819  834  844  845  855  867\n",
      "  882  900  940  962  982  997 1019 1031 1036 1037 1048 1053 1067 1070\n",
      " 1078 1079 1080 1093 1099 1124 1132 1133 1134 1140 1153 1203 1206 1232\n",
      " 1234 1271 1283 1284 1326 1337 1339 1352 1368 1373 1376 1382 1403 1404\n",
      " 1414 1416 1423 1428 1430 1442 1446 1452 1459 1465 1492 1494 1506 1508\n",
      " 1511 1523 1549 1575 1582 1587 1601 1613 1638 1651 1653 1674 1676 1688\n",
      " 1689 1725 1731 1735 1754 1766 1775 1778 1791 1795 1805 1811 1821 1830\n",
      " 1836 1850 1866 1882 1884 1923 1929 1938 1940 1948 1950 1953 1960 1979\n",
      " 2001 2010 2023 2037 2044 2066 2085 2090 2102 2112 2130 2148 2155 2159\n",
      " 2171 2176 2179 2183 2184 2185 2196 2202 2207 2216 2230 2247 2249 2250\n",
      " 2256 2258 2260 2279 2281 2283 2285 2293 2310 2320 2325 2355 2392 2398\n",
      " 2401 2415 2429 2442 2452 2453 2460 2468 2475 2483 2493 2494 2496 2500\n",
      " 2510 2520 2528 2529 2530 2540 2544 2547 2562 2564 2566 2567 2581 2583\n",
      " 2587 2588 2608 2628 2630 2634 2649 2661 2665 2672 2697 2710 2725 2743\n",
      " 2764 2796 2817 2823 2825 2836 2837 2842 2860 2864 2880 2906 2924 2943\n",
      " 2948 2949 2955 2964 2970 2978 2981 2984 2986 2995 2997 3010 3016 3024\n",
      " 3026 3027 3036 3046 3048 3063 3078 3088 3096 3106 3116 3123 3145 3158\n",
      " 3165 3167 3182 3184 3199 3203 3208 3209 3220 3226 3227 3229 3245 3260\n",
      " 3290 3295 3312 3313 3316 3319 3336 3355 3361 3398 3405 3426 3433 3467\n",
      " 3480 3484 3491 3525 3528 3532 3544 3545 3550 3570 3573 3578 3599 3613\n",
      " 3623 3635 3660 3666 3669 3673 3674 3678 3688 3697 3704 3733 3740 3753\n",
      " 3759 3784 3786 3787 3794 3801 3802 3816 3817 3821 3830 3832 3870 3871\n",
      " 3880 3893 3895 3915 3926 3928 3932 3933 3936 3937 3947 3950 3955 3968\n",
      " 3973 3985 3997 4001 4039 4046 4049 4055 4066 4077 4086 4089 4091 4102\n",
      " 4108 4110 4116 4121 4140 4141 4169 4172 4180 4182 4192 4200 4231 4237\n",
      " 4251 4258 4263 4269 4270 4274 4288 4309 4325 4328 4337 4350 4352 4372\n",
      " 4375 4406 4420 4423 4430 4435 4442 4447 4450 4451 4463 4483 4490 4497\n",
      " 4509 4522 4527 4534 4558 4560 4561 4574 4579 4582 4597 4602 4610 4614\n",
      " 4630 4641 4644 4672 4676 4703 4727 4747 4761 4769 4782 4811 4817 4835\n",
      " 4853 4855 4861 4871 4881 4884 4901 4909 4915 4918 4923 4926 4935 4936\n",
      " 4942 4944 4946 4953 4961 4965 4970 4997 5010 5015 5019 5025 5031 5038\n",
      " 5048 5060 5067 5078 5083 5090 5092 5119 5123 5130 5135 5141 5142 5163\n",
      " 5180 5192 5203 5211 5215 5223 5247 5258 5271 5276 5279 5281 5299 5305\n",
      " 5309 5331]\n",
      "TRAIN: [   0    2    3 ... 5338 5339 5340] TEST: [   1   11   13   18   27   35   42   49   50   72   85   89  105  110\n",
      "  128  129  140  142  158  185  207  216  250  269  275  281  300  303\n",
      "  304  306  307  311  316  323  344  349  352  372  374  380  403  406\n",
      "  409  427  440  444  458  459  469  482  489  493  503  514  516  529\n",
      "  548  552  575  587  607  619  629  630  634  636  649  661  664  672\n",
      "  684  687  694  710  714  719  735  743  749  754  786  788  808  821\n",
      "  837  850  858  861  873  890  891  902  916  939  955  961  968  970\n",
      "  986  998 1000 1004 1005 1008 1009 1014 1026 1035 1058 1072 1092 1100\n",
      " 1107 1112 1125 1142 1177 1179 1190 1195 1198 1208 1229 1230 1239 1241\n",
      " 1246 1249 1266 1269 1273 1280 1286 1287 1307 1310 1316 1317 1327 1328\n",
      " 1347 1354 1357 1359 1364 1381 1385 1390 1394 1399 1408 1439 1440 1441\n",
      " 1443 1447 1462 1472 1473 1475 1496 1518 1525 1535 1546 1577 1579 1584\n",
      " 1608 1624 1628 1637 1655 1656 1660 1661 1667 1671 1677 1681 1692 1706\n",
      " 1712 1713 1737 1742 1748 1764 1768 1797 1798 1799 1801 1825 1826 1845\n",
      " 1847 1851 1883 1916 1922 1925 1927 1939 1947 1949 1956 1977 1987 1989\n",
      " 1993 1999 2003 2008 2009 2020 2040 2046 2068 2071 2113 2132 2134 2137\n",
      " 2140 2147 2149 2163 2166 2169 2199 2206 2212 2241 2270 2272 2289 2334\n",
      " 2335 2338 2340 2345 2352 2356 2358 2359 2360 2365 2381 2390 2408 2411\n",
      " 2425 2430 2431 2446 2467 2474 2501 2532 2542 2545 2578 2579 2601 2606\n",
      " 2631 2636 2637 2639 2652 2666 2668 2676 2684 2691 2716 2740 2772 2791\n",
      " 2793 2798 2799 2821 2830 2840 2852 2875 2884 2889 2909 2918 2920 2934\n",
      " 2966 2971 2979 2989 3006 3015 3018 3021 3022 3025 3040 3041 3052 3055\n",
      " 3061 3081 3083 3097 3131 3144 3173 3174 3178 3179 3188 3189 3192 3198\n",
      " 3215 3225 3230 3231 3232 3237 3238 3249 3262 3264 3275 3289 3291 3292\n",
      " 3296 3305 3308 3338 3347 3350 3377 3383 3423 3427 3441 3447 3460 3466\n",
      " 3477 3488 3503 3509 3513 3538 3547 3567 3568 3583 3585 3586 3591 3616\n",
      " 3622 3632 3638 3639 3648 3651 3653 3657 3665 3670 3689 3703 3710 3722\n",
      " 3734 3761 3764 3780 3785 3790 3799 3805 3828 3833 3849 3860 3868 3869\n",
      " 3873 3885 3899 3908 3912 3927 3935 3938 3944 3945 3956 3960 3977 3978\n",
      " 3989 3998 4004 4030 4031 4035 4040 4047 4051 4054 4071 4075 4081 4104\n",
      " 4113 4114 4118 4125 4135 4190 4205 4221 4222 4244 4246 4252 4266 4293\n",
      " 4295 4302 4319 4331 4343 4357 4376 4378 4385 4404 4417 4427 4436 4453\n",
      " 4457 4459 4470 4471 4472 4498 4503 4506 4507 4518 4519 4566 4586 4589\n",
      " 4599 4605 4608 4640 4648 4675 4694 4718 4726 4731 4733 4741 4745 4764\n",
      " 4781 4785 4807 4823 4833 4834 4842 4851 4896 4907 4932 4938 4940 4975\n",
      " 4978 4986 4989 5007 5021 5028 5076 5080 5085 5087 5099 5107 5117 5118\n",
      " 5132 5139 5140 5152 5167 5171 5177 5183 5204 5205 5222 5234 5236 5241\n",
      " 5243 5252 5272 5277 5284 5287 5293 5308 5310 5314 5315 5317 5319 5320\n",
      " 5327 5337]\n",
      "TRAIN: [   0    1    3 ... 5338 5339 5340] TEST: [   2   10   20   21   28   36   37   38   39   40   46   53   60   71\n",
      "   74   83  101  145  148  153  159  165  169  171  186  213  215  236\n",
      "  244  271  273  277  284  294  310  317  329  338  348  355  359  377\n",
      "  390  394  400  425  431  441  447  453  454  473  481  483  515  519\n",
      "  520  526  545  556  571  579  583  585  588  590  591  592  609  614\n",
      "  628  674  686  692  703  704  715  726  730  737  738  750  762  778\n",
      "  780  791  792  795  806  813  824  826  849  868  884  885  886  892\n",
      "  906  913  917  920  933  934  935  936  938  947  963  972  973  974\n",
      "  983  987  988  993 1007 1013 1030 1040 1043 1050 1054 1083 1087 1098\n",
      " 1109 1111 1131 1136 1137 1165 1182 1193 1199 1219 1240 1245 1247 1259\n",
      " 1262 1265 1274 1285 1290 1294 1301 1304 1333 1341 1343 1346 1349 1355\n",
      " 1367 1380 1386 1389 1410 1415 1418 1435 1453 1458 1463 1466 1486 1521\n",
      " 1524 1530 1544 1547 1548 1559 1560 1562 1567 1576 1591 1596 1607 1622\n",
      " 1640 1690 1695 1701 1704 1708 1709 1710 1711 1716 1750 1762 1763 1771\n",
      " 1772 1776 1785 1796 1804 1809 1855 1868 1875 1889 1911 1913 1914 1933\n",
      " 1951 1963 1980 1985 2006 2012 2013 2030 2032 2033 2043 2050 2051 2054\n",
      " 2058 2064 2074 2076 2084 2087 2089 2108 2109 2120 2126 2129 2139 2162\n",
      " 2175 2234 2239 2246 2253 2257 2263 2271 2306 2322 2350 2353 2375 2382\n",
      " 2383 2396 2400 2403 2410 2412 2419 2421 2424 2428 2434 2448 2461 2466\n",
      " 2469 2477 2506 2507 2514 2541 2548 2553 2571 2582 2599 2604 2618 2624\n",
      " 2632 2657 2667 2682 2711 2719 2720 2736 2737 2752 2769 2781 2785 2795\n",
      " 2800 2828 2844 2848 2854 2863 2866 2903 2913 2926 2930 2936 2946 2953\n",
      " 2963 2969 2983 2994 3003 3004 3020 3028 3042 3093 3111 3115 3155 3160\n",
      " 3180 3195 3201 3216 3218 3223 3224 3233 3239 3241 3297 3328 3329 3332\n",
      " 3341 3344 3359 3363 3380 3387 3395 3401 3415 3416 3430 3453 3496 3500\n",
      " 3508 3511 3521 3524 3526 3534 3549 3553 3560 3564 3566 3569 3587 3588\n",
      " 3595 3598 3609 3610 3612 3629 3633 3640 3642 3663 3676 3681 3717 3720\n",
      " 3726 3731 3738 3741 3747 3760 3776 3778 3789 3810 3845 3853 3883 3894\n",
      " 3902 3911 3920 3921 3924 3930 3949 3954 3959 3972 3979 3990 3995 4015\n",
      " 4016 4043 4052 4062 4065 4068 4082 4099 4111 4124 4126 4130 4139 4149\n",
      " 4152 4159 4179 4193 4196 4197 4203 4209 4224 4228 4229 4232 4238 4239\n",
      " 4256 4286 4304 4308 4321 4327 4338 4345 4349 4353 4365 4367 4374 4382\n",
      " 4401 4409 4410 4414 4416 4431 4449 4454 4464 4475 4487 4494 4510 4526\n",
      " 4541 4564 4588 4590 4623 4631 4634 4647 4650 4654 4656 4690 4692 4705\n",
      " 4728 4739 4758 4760 4787 4800 4801 4803 4813 4819 4825 4841 4848 4850\n",
      " 4865 4867 4873 4883 4890 4930 4957 4964 4979 4980 4995 5022 5026 5032\n",
      " 5034 5035 5036 5053 5055 5069 5072 5077 5082 5104 5108 5115 5121 5126\n",
      " 5146 5165 5168 5185 5200 5206 5231 5242 5254 5257 5261 5264 5266 5292\n",
      " 5325 5329]\n",
      "TRAIN: [   0    1    2 ... 5338 5339 5340] TEST: [   3    5    9   54   55   66   77   94  117  125  126  133  137  164\n",
      "  201  223  224  232  235  242  249  255  260  280  285  302  320  327\n",
      "  341  345  357  362  364  375  384  385  388  404  419  455  467  470\n",
      "  477  499  504  510  513  523  525  536  539  603  638  645  666  667\n",
      "  671  673  688  713  716  722  723  760  768  770  774  793  797  814\n",
      "  822  823  827  832  846  872  894  899  901  914  918  919  922  924\n",
      "  928  943  946  950  951  966  984  989  992 1063 1065 1077 1118 1120\n",
      " 1141 1145 1155 1160 1169 1202 1205 1214 1248 1250 1252 1254 1256 1276\n",
      " 1279 1296 1308 1311 1312 1314 1318 1324 1329 1331 1332 1342 1353 1358\n",
      " 1384 1387 1396 1460 1481 1493 1531 1555 1573 1574 1581 1603 1604 1605\n",
      " 1619 1633 1639 1645 1646 1668 1673 1680 1719 1724 1753 1759 1761 1792\n",
      " 1810 1823 1824 1827 1828 1834 1838 1848 1852 1854 1856 1857 1863 1865\n",
      " 1887 1901 1906 1908 1917 1920 1944 1958 1968 1969 1970 1975 1976 1984\n",
      " 1990 1994 1996 1997 2000 2017 2026 2035 2039 2048 2055 2060 2075 2079\n",
      " 2081 2105 2106 2116 2122 2125 2128 2136 2150 2151 2152 2158 2161 2165\n",
      " 2180 2188 2190 2192 2193 2198 2203 2204 2214 2219 2243 2261 2262 2286\n",
      " 2296 2324 2332 2336 2343 2349 2362 2371 2376 2393 2397 2443 2449 2472\n",
      " 2482 2490 2508 2538 2551 2560 2563 2573 2590 2593 2595 2597 2621 2626\n",
      " 2635 2645 2674 2679 2703 2708 2709 2712 2713 2717 2724 2730 2739 2745\n",
      " 2756 2761 2762 2766 2768 2779 2783 2797 2814 2831 2832 2853 2861 2870\n",
      " 2871 2872 2878 2891 2898 2912 2923 2928 2933 2935 2947 2956 2958 2965\n",
      " 3019 3030 3031 3037 3054 3056 3057 3068 3072 3079 3086 3110 3117 3122\n",
      " 3136 3141 3156 3177 3186 3190 3205 3212 3228 3266 3278 3280 3281 3283\n",
      " 3284 3287 3293 3300 3310 3325 3330 3335 3345 3367 3368 3374 3376 3389\n",
      " 3391 3417 3419 3421 3432 3448 3449 3451 3452 3462 3472 3476 3486 3490\n",
      " 3495 3502 3507 3512 3514 3517 3522 3530 3531 3533 3572 3579 3584 3594\n",
      " 3596 3597 3600 3602 3637 3644 3677 3687 3695 3701 3709 3713 3735 3744\n",
      " 3756 3762 3775 3797 3812 3818 3823 3850 3876 3900 3925 3953 3962 3981\n",
      " 3983 4007 4018 4021 4027 4033 4042 4064 4106 4120 4123 4134 4136 4138\n",
      " 4143 4150 4156 4158 4164 4170 4175 4177 4178 4186 4188 4202 4206 4208\n",
      " 4212 4223 4225 4227 4234 4242 4243 4261 4268 4277 4285 4289 4298 4300\n",
      " 4312 4324 4344 4363 4388 4393 4411 4415 4429 4432 4437 4448 4455 4468\n",
      " 4469 4485 4530 4533 4537 4542 4544 4569 4571 4580 4613 4629 4635 4637\n",
      " 4643 4649 4653 4666 4667 4671 4673 4680 4693 4697 4698 4702 4715 4724\n",
      " 4740 4748 4757 4773 4778 4791 4795 4796 4802 4808 4818 4827 4828 4832\n",
      " 4837 4847 4854 4858 4878 4880 4882 4897 4912 4925 4945 4951 4960 4967\n",
      " 4971 4984 4987 5006 5011 5016 5024 5049 5066 5101 5113 5114 5122 5145\n",
      " 5155 5156 5161 5178 5193 5198 5220 5230 5233 5273 5282 5291 5296 5306\n",
      " 5307 5316]\n",
      "TRAIN: [   0    1    2 ... 5338 5339 5340] TEST: [   4   16   34   64   98  114  116  119  127  130  143  146  154  160\n",
      "  161  189  190  197  200  202  206  225  241  253  262  301  335  337\n",
      "  379  391  395  412  417  466  474  488  492  502  512  524  537  559\n",
      "  562  563  569  574  580  595  600  606  608  616  623  635  646  659\n",
      "  663  675  698  699  709  717  728  732  740  753  766  769  775  784\n",
      "  804  815  825  830  851  853  854  860  863  870  876  878  895  953\n",
      "  954  956  959  971  975  980  991  995 1012 1015 1016 1021 1028 1045\n",
      " 1059 1060 1062 1066 1069 1076 1081 1082 1122 1139 1147 1148 1150 1154\n",
      " 1156 1166 1167 1184 1191 1217 1218 1243 1267 1275 1282 1291 1300 1306\n",
      " 1348 1363 1365 1369 1388 1409 1445 1470 1478 1484 1495 1500 1516 1527\n",
      " 1528 1529 1540 1542 1568 1570 1571 1585 1597 1625 1631 1635 1636 1648\n",
      " 1663 1664 1678 1679 1682 1685 1686 1687 1693 1696 1707 1715 1722 1733\n",
      " 1734 1757 1794 1802 1806 1816 1819 1841 1843 1853 1895 1899 1930 1931\n",
      " 1955 1959 1981 1982 1986 1998 2027 2038 2041 2047 2049 2056 2061 2062\n",
      " 2065 2070 2082 2141 2143 2156 2160 2200 2205 2237 2255 2265 2278 2294\n",
      " 2300 2326 2327 2363 2368 2385 2386 2391 2427 2433 2435 2444 2454 2455\n",
      " 2479 2485 2489 2491 2502 2504 2511 2524 2537 2539 2546 2556 2557 2558\n",
      " 2565 2568 2612 2613 2616 2625 2660 2675 2681 2690 2693 2695 2701 2729\n",
      " 2731 2733 2734 2735 2738 2744 2747 2773 2774 2777 2782 2786 2790 2806\n",
      " 2808 2811 2816 2824 2838 2839 2849 2869 2888 2896 2901 2904 2911 2914\n",
      " 2919 2931 2938 2950 2959 2961 2967 2975 2976 2982 2993 2999 3005 3009\n",
      " 3051 3059 3060 3067 3069 3073 3087 3092 3099 3104 3108 3118 3120 3124\n",
      " 3140 3146 3147 3152 3157 3170 3171 3175 3183 3191 3202 3219 3222 3234\n",
      " 3236 3242 3251 3255 3261 3267 3272 3294 3301 3302 3304 3314 3324 3327\n",
      " 3342 3343 3348 3354 3356 3369 3373 3385 3394 3397 3420 3436 3440 3444\n",
      " 3445 3446 3457 3461 3465 3474 3498 3506 3510 3546 3556 3561 3577 3581\n",
      " 3582 3627 3636 3643 3645 3672 3675 3696 3719 3723 3730 3736 3743 3746\n",
      " 3748 3763 3766 3769 3772 3777 3791 3798 3840 3843 3847 3851 3854 3863\n",
      " 3884 3890 3913 3923 3943 3952 3969 3974 3987 3991 3993 4000 4014 4029\n",
      " 4045 4057 4061 4067 4070 4079 4090 4097 4107 4115 4117 4131 4132 4142\n",
      " 4146 4171 4185 4191 4199 4218 4249 4276 4282 4297 4330 4341 4360 4364\n",
      " 4380 4389 4413 4426 4433 4452 4465 4474 4488 4491 4492 4493 4495 4496\n",
      " 4499 4514 4548 4551 4555 4565 4583 4592 4598 4611 4636 4642 4646 4658\n",
      " 4659 4682 4721 4723 4729 4735 4736 4737 4744 4752 4754 4777 4779 4780\n",
      " 4798 4799 4843 4859 4869 4875 4887 4891 4893 4902 4911 4929 4931 4933\n",
      " 4948 4950 4954 4972 4973 4976 4990 5047 5051 5054 5056 5062 5068 5105\n",
      " 5106 5110 5116 5133 5134 5147 5150 5164 5191 5199 5213 5224 5225 5226\n",
      " 5237 5246 5248 5262 5267 5269 5283 5285 5286 5289 5311 5321 5322 5330\n",
      " 5332 5334]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "kf = KFold(n_splits=10,shuffle=True, random_state=42)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "print(kf)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running a new one...\n",
      "\n",
      " # of train:4806; # of test:535; total #:5341\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 59, 128)           512       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 59, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 29, 128)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 29, 128)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3712)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 3713      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,225\n",
      "Trainable params: 4,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b18c06dd8290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mhistory_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mcvscores_fscore_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/student_prediction/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/student_prediction/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/student_prediction/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/student_prediction/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/student_prediction/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/student_prediction/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/student_prediction/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/student_prediction/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/envs/student_prediction/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cvscores_accuracy = []\n",
    "cvscores_fscore = []\n",
    "cvscores_auc = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    cvscores_fscore_temp = 0\n",
    "    print(\"\\nRunning a new one...\")\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print('\\n # of train:{}; # of test:{}; total #:{}'.format(len(X_train), len(X_test), len(X_train)+len(X_test)))\n",
    "    \n",
    "    lr=0.00001\n",
    "    epochs = 1000\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=128,kernel_size=3, strides=2, input_shape=X_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool1D(pool_size=2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "              metrics=['accuracy','Recall','Precision','AUC'])\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    history_model = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=128,verbose=0)    \n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    cvscores_fscore_temp = (2*scores[2]*scores[3])/(scores[2]+scores[3])\n",
    "    print(scores[1])\n",
    "    print(cvscores_fscore_temp)\n",
    "    print(scores[4])\n",
    "\n",
    "    cvscores_accuracy.append(scores[1] * 100)\n",
    "    cvscores_fscore.append(cvscores_fscore_temp * 100)\n",
    "    cvscores_auc.append(scores[4] * 100)\n",
    "\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores_accuracy), np.std(cvscores_accuracy)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores_fscore), np.std(cvscores_fscore)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores_auc), np.std(cvscores_auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history_model.history).plot(figsize=(10, 7))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "88.19% (+/- 0.59%)\n",
    "91.84% (+/- 0.46%)\n",
    "90.88% (+/- 0.81%)\n",
    "\n",
    "lr=0.001\n",
    "epochs = 400\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=128,kernel_size=3, strides=2, input_shape=X_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool1D(pool_size=2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86.91% (+/- 1.10%)\n",
    "90.97% (+/- 0.81%)\n",
    "88.69% (+/- 1.45%)\n",
    "\n",
    "lr=0.00001\n",
    "epochs = 1000\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=128,kernel_size=3, strides=2, input_shape=X_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool1D(pool_size=2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "776263c496be5c6ef9b62855ccfe4216cc9e3bb1bb92391165ff82701524ab45"
  },
  "kernelspec": {
   "display_name": "student_prediction",
   "language": "python",
   "name": "student_prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
